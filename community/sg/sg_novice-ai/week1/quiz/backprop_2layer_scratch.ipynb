{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUK3xEEXKWvu"
   },
   "source": [
    "Q15) Given a neural network having a1,a2 as inputs, c1,c2 as outputs ,h1, h2 nodes of hidden layer and b1,b2 as biases. Network is initialized with the values and weights given in the graph? Your task is to perform 1 step of backpropagation and give the updated values for the weight w5 and w6.\n",
    "\n",
    "<!--<img src=\"../img/quiz-backprop.jpg\"> -->\n",
    "<img src=\"https://lh5.googleusercontent.com/TxfaejDZ4C1x5DCz8T_kPGDZaH-cWv5gonRIeDfNJEeqcZZEX-CKajkifliEwH0uTcB53g6xfQ=w740\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHthiWCvEIx_"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bMKP8YP0Bqwo"
   },
   "outputs": [],
   "source": [
    "a1 = torch.tensor([[0.05]], requires_grad=True)\n",
    "a2 = torch.tensor([[0.10]], requires_grad=True)\n",
    "\n",
    "b1 = torch.tensor([[0.35]], requires_grad=True)\n",
    "b2 = torch.tensor([[0.60]], requires_grad=True)\n",
    "\n",
    "w1 = torch.tensor([[0.15]], requires_grad=True)\n",
    "w2 = torch.tensor([[0.20]], requires_grad=True)\n",
    "w3 = torch.tensor([[0.25]], requires_grad=True)\n",
    "w4 = torch.tensor([[0.30]], requires_grad=True)\n",
    "\n",
    "w5 = torch.tensor([[0.40]], requires_grad=True)\n",
    "w6 = torch.tensor([[0.45]], requires_grad=True)\n",
    "w7 = torch.tensor([[0.50]], requires_grad=True)\n",
    "w8 = torch.tensor([[0.55]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "lixn2Jm4C6ax",
    "outputId": "772a051d-031f-475f-a24e-4820f4691cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3775]], grad_fn=<AddBackward0>)\n",
      "tensor([[0.3925]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "h1 = a1*w1 + a2*w2 + b1\n",
    "h2 = a1*w3 + a2*w4 + b1\n",
    "\n",
    "print(h1)\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "PdTmqxsVEfhN",
    "outputId": "75a5df3c-fe28-48b0-9173-598ed46bc457"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9276]], grad_fn=<AddBackward0>)\n",
      "tensor([[1.0046]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c1 = h1*w5 + h2*w6 + b2\n",
    "c2 = h1*w7 + h2*w8 + b2\n",
    "\n",
    "print(c1)\n",
    "print(c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "-cVvA_zQFoXK",
    "outputId": "5006c0d3-a3f9-4964-cde6-7eb80b934e32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The gradient isn't set, right? False\n"
     ]
    }
   ],
   "source": [
    "# w5 and w6 are connected to c1\n",
    "\n",
    "print(f\"The gradient isn't set, right? {bool(w5.grad)}\")\n",
    "\n",
    "# call backward() on c1 to populate gradients in all tensors in its calculation\n",
    "c1.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "IJKpG9wjIclA",
    "outputId": "694e135a-a4a8-4716-919b-a124f697fd38"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the gradient set now? True\n",
      "The gradient of w5: 0.3775\tw6: 0.3925\n"
     ]
    }
   ],
   "source": [
    "print(f\"Is the gradient set now? {bool(w5.grad)}\")\n",
    "print(F\"The gradient of w5: {w5.grad.item():.4f}\\tw6: {w6.grad.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S8XO-wB5I2V2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated values after one step of backprop w5:0.324\tw6:0.371\n"
     ]
    }
   ],
   "source": [
    "# let learning rate be 0.2\n",
    "with torch.no_grad():\n",
    "  lr = 0.2\n",
    "  w5 = w5 - w5.grad * 0.2\n",
    "  w6 = w6 - w6.grad * 0.2\n",
    "print(f\"Updated values after one step of backprop w5:{w5.item():.3f}\\tw6:{w6.item():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "backprop-2layer-scratch.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
