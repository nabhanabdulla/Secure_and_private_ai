{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let **weights** be a tensor\n",
    "\n",
    "* `weights.reshape(a, b)` will return a new tensor with the same data(points to the same memory location) as `weights` with size `(a, b)` sometimes, and sometimes a clone, as in it copies the data to another part of memory.\n",
    "* `weights.resize_(a, b)` returns the same tensor with a different shape. However, if the new shape results in fewer elements than the original tensor, some elements will be removed from the tensor (but not from memory). If the new shape results in more elements than the original tensor, new elements will be uninitialized in memory. Here I should note that the underscore at the end of the method denotes that this method is performed **in-place**. Here is a great forum thread to [read more about in-place operations](https://discuss.pytorch.org/t/what-is-in-place-operation/16244) in PyTorch.\n",
    "* `weights.view(a, b)` will return a new tensor with the same data as `weights` with size `(a, b)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4333]) tensor([-1.3594])\n",
      "x: 2659434368240, y: 2659434368744\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.randn(1)\n",
    "y = torch.randn(1)\n",
    "\n",
    "print(x, y)\n",
    "print(f'id(x): {id(x)}, id(y): {id(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([-0.9262]) id(x) = 2659434365432\n"
     ]
    }
   ],
   "source": [
    "x = x + y # Normal operation \n",
    "print(f'x = {x} id(x) = {id(x)}') # New location for x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([-2.2856]) id(x) = 2659434365432\n"
     ]
    }
   ],
   "source": [
    "x += y # inplace operation\n",
    "print(f'x = {x} id(x) = {id(x)}') # existing location used(in-place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = tensor([-3.6450]) id(x) = 2659434365432\n"
     ]
    }
   ],
   "source": [
    "x.add_(y) # inplace operation\n",
    "print(f'x = {x} id(x) = {id(x)}') # existing location used(in-place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inplace operations in pytorch are always postfixed with a _ , like .add_() or .scatter_(). Python operations like += or *= are also inplace operations.**\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy to Torch and back\n",
    "\n",
    "Special bonus section! PyTorch has a great feature for converting between Numpy arrays and Torch tensors. To create a tensor from a Numpy array, use `torch.from_numpy()`. To convert a tensor to a Numpy array, use the `.numpy()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30467821, 0.16646286, 0.15526558],\n",
       "       [0.80200092, 0.76872907, 0.01923306],\n",
       "       [0.87637473, 0.64626048, 0.55101986],\n",
       "       [0.5537705 , 0.03527895, 0.62079543]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.random.rand(4,3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3047, 0.1665, 0.1553],\n",
       "        [0.8020, 0.7687, 0.0192],\n",
       "        [0.8764, 0.6463, 0.5510],\n",
       "        [0.5538, 0.0353, 0.6208]], dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30467821, 0.16646286, 0.15526558],\n",
       "       [0.80200092, 0.76872907, 0.01923306],\n",
       "       [0.87637473, 0.64626048, 0.55101986],\n",
       "       [0.5537705 , 0.03527895, 0.62079543]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory is shared between the Numpy array and Torch tensor, so if you change the values in-place of one object, the other will change as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6094, 0.3329, 0.3105],\n",
       "        [1.6040, 1.5375, 0.0385],\n",
       "        [1.7527, 1.2925, 1.1020],\n",
       "        [1.1075, 0.0706, 1.2416]], dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply PyTorch Tensor by 2, in place\n",
    "b.mul_(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60935641, 0.33292571, 0.31053115],\n",
       "       [1.60400185, 1.53745814, 0.03846612],\n",
       "       [1.75274946, 1.29252097, 1.10203971],\n",
       "       [1.107541  , 0.07055789, 1.24159087]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array matches new values from Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the training data loaded into `trainloader` and we make that an iterator with `iter(trainloader)`. Later, we'll use this to loop through the dataset for training, like\n",
    "\n",
    "```python\n",
    "for image, label in trainloader:\n",
    "    ## do things with images and labels\n",
    "```\n",
    "\n",
    "You'll notice I created the `trainloader` with a batch size of 64, and `shuffle=True`. The batch size is the number of images we get in one iteration from the data loader and pass through our network, often called a *batch*. And `shuffle=True` tells it to shuffle the dataset every time we start going through the data loader again. But here I'm just grabbing the first batch so we can check out the data. We can see below that `images` is just a tensor with size `(64, 1, 28, 28)`. So, 64 images per batch, 1 color channel, and 28x28 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = images.view(images.shape[0], -1)\n",
    "inputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a multi-layer network with 784 input units, 256 hidden units, and 10 output units using random tensors for the weights and biases. For now, use a sigmoid activation for the hidden layer and leave the output without one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([[-3.2193e+00, -1.7023e+01, -1.3395e+01,  3.6186e+00,  2.2172e+01,\n",
      "         -2.5518e+01,  1.1408e+01, -6.8785e+00, -7.0721e+00, -4.2442e+00],\n",
      "        [ 7.1757e+00, -6.8673e+00, -5.8979e+00,  5.9031e+00,  1.2552e+01,\n",
      "         -2.3809e+01,  1.6297e+01, -1.0659e+01, -3.8191e+00, -6.6499e+00],\n",
      "        [ 3.7525e+00, -3.2684e+00, -7.5519e+00,  1.2205e+01,  8.7440e+00,\n",
      "         -1.8315e+01,  5.4285e+00, -1.2586e+00, -6.3982e+00, -8.1119e+00],\n",
      "        [-1.5672e+00, -1.2791e+01, -5.9504e+00,  8.0067e+00,  8.8310e+00,\n",
      "         -1.1849e+01,  1.5828e+01, -4.0509e+00,  8.5285e-01,  6.4194e-01],\n",
      "        [ 2.2889e+00, -5.7570e+00,  9.4711e-01,  6.7611e+00,  1.5003e+01,\n",
      "         -2.2965e+01,  4.1218e+00, -7.5616e+00, -1.9083e+01, -1.4526e+00],\n",
      "        [ 8.2334e+00, -2.2868e+00, -1.2525e+01,  9.6182e+00,  9.3221e+00,\n",
      "         -2.2471e+01,  1.5176e+01, -1.1543e+01, -4.0032e+00, -4.7276e+00],\n",
      "        [ 4.1577e+00,  3.3112e-01, -6.7389e+00,  8.2080e+00,  1.8484e+01,\n",
      "         -1.3008e+01,  1.0792e+01, -1.2080e+01, -9.4610e+00, -1.0143e+01],\n",
      "        [-6.2555e+00, -1.2231e+01, -5.1595e+00, -3.5310e+00,  2.2082e+01,\n",
      "         -2.2240e+00,  5.5018e+00, -8.9208e+00, -3.4941e+00, -7.1759e-01],\n",
      "        [ 2.9212e+00, -7.9436e+00,  4.1555e-01,  9.9850e+00,  1.6346e+01,\n",
      "         -1.8035e+01,  7.7064e+00, -6.2744e+00, -1.1544e+01,  2.7576e+00],\n",
      "        [ 4.9042e+00, -3.6634e+00, -1.6936e+01,  1.2393e+00,  1.4479e+01,\n",
      "         -9.5224e+00,  5.7671e+00, -1.1957e+01, -1.8186e+00, -6.6788e+00],\n",
      "        [ 4.1270e+00, -3.2533e+00, -1.3216e+01,  4.6242e+00,  2.8550e+01,\n",
      "         -1.9754e+01,  9.2540e+00, -9.2001e+00,  1.1584e+00,  4.9801e+00],\n",
      "        [-2.8416e+00, -1.0620e+01, -6.6832e+00,  1.1592e+01,  1.5512e+01,\n",
      "         -1.4057e+01,  9.1190e+00,  1.1370e+00,  8.0458e-01,  8.1979e+00],\n",
      "        [ 9.5883e+00, -8.2677e+00, -3.7059e-02,  1.1694e+01,  7.5101e+00,\n",
      "         -1.2745e+01,  7.3506e+00, -1.1278e+00, -8.7408e+00, -9.5592e+00],\n",
      "        [ 6.4314e+00, -1.0376e+01,  5.4995e+00,  6.5822e+00,  1.8843e+01,\n",
      "         -1.0706e+01,  8.9291e+00,  7.5139e+00, -4.1928e+00, -5.2824e+00],\n",
      "        [ 1.8546e+00,  7.4429e-02, -8.7786e+00,  4.2936e+00,  2.5328e+01,\n",
      "         -2.3867e+01,  5.4163e+00, -1.4141e+01, -1.3248e+01,  6.6623e-01],\n",
      "        [-1.6444e+00, -3.6502e+00, -4.6570e+00,  4.1624e+00,  1.7070e+01,\n",
      "         -2.7845e+01,  1.4690e+01, -1.4285e+01, -6.6626e+00, -1.3809e+00],\n",
      "        [ 1.5617e+00, -8.3878e+00, -3.9767e+00,  1.3037e+01,  2.7033e+01,\n",
      "         -2.2858e+01,  2.1937e+01, -4.9252e+00, -5.3129e+00, -6.4920e+00],\n",
      "        [ 7.8200e+00,  2.4125e+00, -7.7685e+00,  7.5391e+00,  1.0453e+01,\n",
      "         -7.4311e+00,  1.0016e+01, -7.1179e+00,  1.7658e-01, -2.0772e+00],\n",
      "        [ 1.0137e+00, -3.5885e+00, -5.9858e+00,  1.8757e+01,  2.5596e+01,\n",
      "         -1.6936e+01,  2.2947e+01, -1.4983e+00, -4.8467e-01, -1.2805e+00],\n",
      "        [-7.5375e-01, -1.1982e+00, -1.1440e+01,  1.6879e+01,  1.9387e+01,\n",
      "         -2.2364e+01,  9.7185e+00, -5.7166e-01, -7.7366e+00, -4.7057e+00],\n",
      "        [-6.8153e+00,  6.3471e-01, -1.0010e+01,  9.6519e-01,  1.4832e+01,\n",
      "         -2.2525e+01,  1.1013e+01,  2.4778e+00, -2.8413e+00, -5.5438e+00],\n",
      "        [-1.7408e+00, -1.4601e+01,  1.3734e+00,  9.3315e+00,  2.4042e+01,\n",
      "         -2.6085e+01,  1.7188e+01,  4.2565e+00, -3.4048e+00,  3.3933e+00],\n",
      "        [-5.0822e-01, -3.8501e+00, -6.9198e+00,  7.5276e+00,  2.0272e+01,\n",
      "         -1.3021e+01,  1.4702e+00, -1.1180e+01, -1.2771e+01, -4.3608e-01],\n",
      "        [ 5.2838e+00,  8.5943e-01, -7.6264e+00,  7.8847e+00,  1.5802e+01,\n",
      "         -2.3088e+01,  1.5878e+01,  4.0658e+00, -2.9638e+00,  1.7750e+00],\n",
      "        [-3.1614e+00, -7.2003e+00,  2.7939e+00,  8.5178e+00,  2.2388e+01,\n",
      "         -1.4842e+01,  1.2278e+01, -5.4694e+00, -6.6419e+00, -1.1351e+01],\n",
      "        [ 6.0516e+00, -1.5554e+01, -5.9144e+00,  7.7338e+00,  9.6998e+00,\n",
      "         -2.4986e+01,  7.8391e+00, -4.3292e+00, -1.4793e+00, -5.2927e-01],\n",
      "        [-1.3575e+00,  1.2613e+00, -1.8433e+00,  3.4821e+00,  1.4144e+01,\n",
      "         -2.3608e+01,  2.0468e+01, -5.2565e+00, -1.1947e+01, -1.0225e+01],\n",
      "        [ 1.7939e+00, -4.2329e+00, -8.9316e+00,  1.0826e+00,  3.4419e+01,\n",
      "         -2.2525e+01,  5.9137e+00,  1.9588e+00, -5.4317e+00,  3.0148e+00],\n",
      "        [-2.1893e+00, -4.0627e+00, -1.0624e+01,  7.6314e-01,  2.7237e+01,\n",
      "         -1.8294e+01,  3.8274e+00,  7.6082e+00, -5.7204e+00,  9.4707e-01],\n",
      "        [-2.7982e+00, -4.0458e+00,  4.4608e+00,  7.4416e+00,  1.5977e+01,\n",
      "         -2.3360e+01,  1.9744e+01, -1.8930e+00, -2.2394e+00, -6.7443e+00],\n",
      "        [-4.4676e+00, -5.8709e+00, -1.2946e+01, -3.6710e-01,  2.0703e+01,\n",
      "         -2.0666e+01,  1.1664e+01, -6.0469e+00, -6.0527e+00, -5.6658e+00],\n",
      "        [ 1.3832e+00, -2.9117e+00, -9.0499e+00,  7.7540e+00,  1.4198e+01,\n",
      "         -3.0540e+01,  1.3604e+01, -1.4026e+01, -4.0361e+00, -7.7019e+00],\n",
      "        [ 1.4167e+00, -1.2103e+01, -2.5856e+00,  1.2417e+01,  1.6607e+01,\n",
      "         -2.1265e+01,  9.6418e+00,  8.5469e+00,  3.9003e+00, -6.3807e+00],\n",
      "        [ 3.7415e+00, -4.0096e+00, -1.5584e+01,  7.5054e+00,  1.7101e+01,\n",
      "         -1.0509e+01,  1.1656e+01, -3.7673e+00, -2.9037e+00,  4.4005e-01],\n",
      "        [ 2.0525e+00,  3.7240e+00, -5.4343e-01,  1.1014e+01,  2.1833e+01,\n",
      "         -1.2126e+01,  1.6412e+01, -5.3478e+00, -3.8569e+00, -3.4165e+00],\n",
      "        [-2.6501e+00, -2.6112e+00, -2.0266e+01,  7.1865e+00,  1.7551e+01,\n",
      "         -1.5085e+01,  3.1379e+00, -7.3988e+00, -6.2186e+00, -1.6952e+00],\n",
      "        [ 1.1184e+01, -2.7109e+00, -7.9480e+00,  2.1843e+00,  2.4222e+01,\n",
      "         -1.4870e+01,  1.4499e+01, -6.6820e+00, -6.9218e+00, -4.9120e+00],\n",
      "        [-1.6580e+00,  2.4144e+00, -1.3714e+01,  3.3561e+00,  1.1915e+01,\n",
      "         -2.5038e+01,  1.4202e+01, -2.7369e+00, -7.5507e+00, -5.2918e+00],\n",
      "        [-2.6196e+00, -5.2877e+00, -1.1180e+01,  2.8183e-02,  2.5875e+01,\n",
      "         -1.9807e+01,  2.1668e+00, -3.8187e+00, -7.7834e+00, -6.1151e+00],\n",
      "        [ 4.9235e+00, -7.0515e+00, -1.1324e+01,  6.1555e+00,  2.2093e+01,\n",
      "         -2.4106e+01,  1.4921e+01,  3.2988e+00, -1.9079e-01, -4.4102e+00],\n",
      "        [ 3.3295e+00, -3.1342e+00, -1.0257e+01,  4.4170e+00,  1.6579e+01,\n",
      "         -3.9120e+00,  7.3900e+00, -8.9084e+00, -5.2432e+00, -2.4025e+00],\n",
      "        [ 4.1064e+00,  2.1546e+00, -4.8670e-01, -1.1016e+00,  9.7180e+00,\n",
      "         -7.6221e+00,  7.2636e+00, -1.0300e+01, -1.1798e+01, -1.6094e+00],\n",
      "        [-7.9776e-01, -3.2754e+00, -1.1857e+01, -4.5587e-01,  2.9454e+01,\n",
      "         -2.1808e+01,  3.1359e+00,  1.4242e+00, -8.4213e+00,  1.2450e+00],\n",
      "        [-1.7954e+00, -1.0349e+01, -4.3994e+00,  6.5453e+00,  1.7370e+01,\n",
      "         -3.8593e+00,  1.4545e+01, -2.7759e+00,  3.1437e+00, -6.4224e+00],\n",
      "        [ 9.8161e+00, -1.3144e-01, -1.3785e+00,  3.8623e+00,  2.1394e+01,\n",
      "         -1.4065e+01,  8.0595e+00,  1.0046e+00, -3.0872e+00,  6.7777e+00],\n",
      "        [ 3.8255e+00, -6.1713e+00, -8.3974e+00,  5.1841e+00,  2.4136e+01,\n",
      "         -2.5808e+01,  1.1786e+01, -3.1496e+00, -1.2009e+01, -2.1805e+00],\n",
      "        [ 1.0515e+01, -5.0939e+00,  4.1335e+00,  5.8482e+00,  1.9435e+01,\n",
      "         -1.1735e+01,  5.1068e+00, -1.1836e+01, -8.5647e+00, -1.1469e+00],\n",
      "        [-5.7091e+00, -6.3901e+00, -1.6793e+01,  7.0985e+00,  1.8850e+01,\n",
      "         -1.9309e+01,  1.3192e+01, -1.0011e+01, -6.0487e+00, -2.9221e+00],\n",
      "        [-9.8760e+00, -8.7512e+00, -1.1065e+01,  4.6598e+00,  1.1154e+01,\n",
      "         -1.1998e+01,  1.1331e+01, -5.0250e+00, -9.3475e+00,  1.1636e-01],\n",
      "        [ 2.3029e-01, -2.2517e+00, -3.2213e+00,  6.9311e+00,  9.8835e+00,\n",
      "         -8.7695e+00,  9.8676e+00,  1.7990e+00, -1.6787e+01,  3.6333e+00],\n",
      "        [-3.8146e+00, -6.6221e+00, -1.9117e+01,  1.2742e+01,  1.2271e+01,\n",
      "         -7.7819e+00,  3.3820e+00, -1.7403e+01, -9.8243e+00, -6.8315e+00],\n",
      "        [ 2.0736e+00, -5.9181e+00, -3.6662e+00,  1.5143e+00,  2.0009e+01,\n",
      "         -9.2733e+00,  1.3146e+00,  5.7012e+00, -9.4441e+00,  2.3992e+00],\n",
      "        [ 3.6335e+00, -1.2015e+01, -9.2734e+00,  1.4276e+01,  1.8045e+01,\n",
      "         -2.5344e+01,  1.0232e+01, -1.1342e+01,  4.1581e+00,  6.0248e+00],\n",
      "        [ 7.1199e+00, -1.4094e+00, -3.9945e+00,  6.2538e+00,  1.5135e+01,\n",
      "         -2.1546e+01,  1.1404e+01, -1.1792e+01, -9.5909e+00,  6.2881e-01],\n",
      "        [ 6.7994e+00, -4.6764e+00, -1.3566e+00,  1.1767e+01,  2.5192e+01,\n",
      "         -2.1753e+01,  8.3921e+00, -9.9166e+00, -3.4123e+00, -3.5640e+00],\n",
      "        [-2.5390e+00, -1.2589e+01, -5.8789e+00, -2.2326e+00,  1.9933e+01,\n",
      "         -1.5361e+01,  1.6244e+01,  4.0147e-01, -5.1471e+00,  2.2176e+00],\n",
      "        [ 1.5090e+00, -1.3940e+01, -8.1990e+00, -3.7107e+00,  2.2030e+01,\n",
      "         -1.6034e+01,  6.5030e+00, -1.6758e+01, -1.5746e+01, -4.5289e-01],\n",
      "        [ 5.3704e+00, -1.1092e+01,  3.3072e+00,  9.7532e+00,  2.3342e+01,\n",
      "         -1.9112e+01,  1.4669e+01, -1.1837e+00, -4.5071e+00,  1.0097e+00],\n",
      "        [ 5.9653e+00, -1.9218e+01, -3.3513e+00,  7.1426e+00,  2.0923e+01,\n",
      "          1.3393e+00,  1.5257e+01, -8.6636e+00, -1.1029e+01, -1.0956e+01],\n",
      "        [ 1.1726e+01, -6.8150e+00, -6.9364e+00,  9.5442e+00,  1.8436e+01,\n",
      "         -1.4906e+01,  1.0940e+01, -7.8374e+00, -7.1547e+00, -2.2251e+00],\n",
      "        [ 5.2038e-01,  3.6497e-01, -1.6701e+01, -7.6653e+00,  1.7200e+01,\n",
      "         -8.9538e+00,  9.9744e+00, -8.7865e+00, -3.7138e+00, -7.8639e+00],\n",
      "        [-1.9154e+00, -2.0586e+00, -6.2772e+00,  9.2891e+00,  2.2816e+01,\n",
      "         -2.6941e+01,  2.1919e+01, -4.1463e+00, -3.1328e+00, -1.5377e+01],\n",
      "        [ 8.3483e-01, -7.9379e+00, -1.0910e+01,  3.1505e+00,  2.1738e+01,\n",
      "         -1.0255e+01,  1.1446e+01, -1.4100e+01, -5.1174e+00, -6.2882e+00],\n",
      "        [-5.8591e+00, -1.0064e+00, -4.3016e+00,  1.0540e+01,  2.1167e+01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         -2.4220e+01,  1.7294e+01,  2.8112e+00, -3.1712e+00, -1.2298e+01]])\n"
     ]
    }
   ],
   "source": [
    "## Your solution\n",
    "np.random.seed(7)\n",
    "\n",
    "def activation(x):\n",
    "    return 1 / (1 + torch.exp(-x)) # or np.exp(-x)\n",
    "\n",
    "# Flatten the input image\n",
    "inputs = images.view(images.shape[0], -1)# or images.view(64, 784)\n",
    "\n",
    "# Set network layer sizes\n",
    "n_input = inputs.shape[1] # 784\n",
    "n_hidden = 256\n",
    "n_output = 10\n",
    "\n",
    "# Create parameters\n",
    "W1 = torch.randn(n_input, n_hidden) # weights for the hidden layer- 784X256\n",
    "W2 = torch.randn(n_hidden, n_output) # weights for the output layer- 256X10\n",
    "\n",
    "B1 = torch.randn(1, n_hidden) # biases for the hidden layer- 1X256\n",
    "B2 = torch.randn(1, n_output) # biases for the output layer- 1X10\n",
    "\n",
    "# output of hidden layer- 64X256 ie 1X256 values for 64 images in the batch\n",
    "# torch.mm(inputs, W1)- 64X256\n",
    "# even though B1 is of shape 1X256, it broadcasts to 64X256 when made to add with a 64X256 matrix\n",
    "h = activation(torch.mm(inputs, W1) + B1) \n",
    "\n",
    "# torch.mm(h, W2)- 64X10\n",
    "# B2 broadcasts from 1X10 to 64X10 on addition with a 64X10 matrix\n",
    "out = torch.mm(h, W2) + B2 # network output- 64X10 ie 10 output values for each of 64 images\n",
    "\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    num = torch.exp(x)\n",
    "    den = torch.sum(torch.exp(x), dim=1).view(-1, 1) # change shape from (64, ) to (64, 1).\n",
    "    return num/den\n",
    "\n",
    "# Here, out should be the output of the network in the previous excercise with shape (64,10)\n",
    "probabilities = softmax(out)\n",
    "\n",
    "# Does it have the right shape? Should be (64, 10)\n",
    "print(probabilities.shape)\n",
    "# Does it sum to 1?\n",
    "print(probabilities.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "den = torch.sum(torch.exp(out), dim=1)\n",
    "den.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.Size([64])** ~ **numpy (64, )** it is considered to be **(1, 64)** during broadcasting.\n",
    "\n",
    "So if we divide (64, 10) the numerator with (64, ), python will try to broadcast to make the tensors of same size.\n",
    "(64, ) to (1, 64) to ?\n",
    "\n",
    "(64, 10) and (1, 64) can't be broadcasted to equal size and python outputs error.\n",
    "\n",
    "Now if we reshape (64, ) to (64, 1), the broadcasting goes like this,\n",
    "(64, 1) to (64, 10)\n",
    "\n",
    "Now, (64, 10) the numerator and (64, 10) the broadcasted denominator can be divided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ready-made NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network3L(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Your solution here\n",
    "from torch import nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "# 3 layer NN\n",
    "class Network3L(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # first fc hidden layer\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "\n",
    "        # second fc hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "\n",
    "        # fc output layer\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x)) # output of first hidden layer\n",
    "        h2 = F.relu(self.fc2(h1)) # output of second hidden layer\n",
    "        out = F.sigmoid(self.fc3(h2)) # neural network output\n",
    "        \n",
    "model = Network3L()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 784]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "print(model.fc1.weight.shape, model.fc1.bias.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `nn.Sequential`\n",
    "\n",
    "PyTorch provides a convenient way to build networks like this where a tensor is passed sequentially through operations, `nn.Sequential` ([documentation](https://pytorch.org/docs/master/nn.html#torch.nn.Sequential)). Using this to build the equivalent network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for our network\n",
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.Softmax(dim=1))\n",
    "print(model)\n",
    "\n",
    "# Forward pass through the network and display output\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(images.shape[0], 1, 784)\n",
    "ps = model.forward(images[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(6, 9))\n",
    "\n",
    "ax[0].imshow(images[0].view(28, 28))\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].barh(np.arange(10), ps.data.numpy().squeeze())\n",
    "ax[1].set_aspect(0.1)\n",
    "ax[1].set_xlim(0, 1.1)\n",
    "ax[1].set_yticks(np.arange(10))\n",
    "ax[1].set_yticklabels(np.arange(10))\n",
    "ax[1].set_title('Class Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "#helper.view_classify(images[0].view(1, 28, 28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
