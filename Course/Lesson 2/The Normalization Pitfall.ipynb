{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Problem: Inconsistency of `transforms.Normalize` across plaforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement\n",
    "* The problem we are trying to investigate is that `torchvision.transforms.Normalize` shows different behaviour across platforms\n",
    "\n",
    "* When the transform `Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))` is used on images with a single color channel(eg: grayscale images) it runs fine or shows error like `RuntimeError: output with shape [1, 28, 28] doesn't match the broadcast shape [3, 28, 28]` depending on the platform you use\n",
    "\n",
    "This is the code snippet we are focusing on\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                              ])\n",
    "\n",
    "# Download and load the test data\n",
    "dataset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "img, label = next(iter(dataloader))\n",
    "img.shape\n",
    "\n",
    "**TL;DR: The discrepancy is caused by differences in torchvision versions installed**\n",
    "\n",
    "#### Resources\n",
    "\n",
    "* Three platforms are taken into consideration:\n",
    "    1. **Udacity workspace** (torch 0.4.0 torchvision 0.2.1)\n",
    "        <p style=\"font-size:20;font-weight:bolder;text-align:center\">Udacity Workspace</p>\n",
    "        <img src=\"../../Screenshots/normalize_udacity_workspace.png\">\n",
    "        \n",
    "    2. **Local machine** (torch 1.0.1 torchvision 0.2.2)\n",
    "        <p style=\"font-size:20;font-weight:bolder;text-align:center\">Local Machine</p>\n",
    "        <img src=\"../../Screenshots/normalize_local_machine.png\">\n",
    "    \n",
    "\t3. **Google Colab** (torch 1.1.0 torchvision 0.3.0)\n",
    "        <p style=\"font-size:20;font-weight:bolder;text-align:center\">Google Colaboratory</p>\n",
    "        <img src=\"../../Screenshots/normalize_colab.png\">\n",
    "    \n",
    "    \n",
    "* Dataset used - **Fashion MNIST**\n",
    "\n",
    "#### Get a sample image\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download=True, train=False, transform=transform)\n",
    "\n",
    "img, label = dataset[0]\n",
    "print(img.shape, type(img))\n",
    "\n",
    "#### Investigate source code\n",
    "\n",
    "Use this code to get source code:\n",
    ">>> import inspect\n",
    ">>> print(inspect.getsource(transforms.transforms.Normalize)) # Normalize - is a class hence starts with capital letter\n",
    ">>> print(inspect.getsource(transforms.functional.normalize)) # normalize - is a function thus uses lowercase\n",
    "\n",
    "Nb: For more Python conventions on naming, see [PEP-8 Style Guide](https://www.python.org/dev/peps/pep-0008/#naming-conventions)\n",
    "\n",
    "Let's take a deep dive into the source code for `Normalize` class in `torchvision.transforms.transforms`:\n",
    "\n",
    "##### 1) `transforms.transforms.Normalize`\n",
    "\n",
    "NB: Some of the comments and parts irrevelant for our discussion has been removed for brevity and for keeping the focus on the problem at hand\n",
    "\n",
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean, std, inplace=False):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized Tensor image.\n",
    "        \"\"\"\n",
    "        return F.normalize(tensor, self.mean, self.std, self.inplace)\n",
    "\n",
    "* **Confused how `__init__` and `__call__` differs? See [this](https://stackoverflow.com/a/54881816/9734484) answer @ stack overflow**\n",
    "\n",
    "\n",
    "* **the arguments are named self.---- because they are called inside python classes**\n",
    "\n",
    "* `tensor` in argument to `__call__` is the tensor on which we call `Normalize`\n",
    "* The class calls `F.normalize(tensor, self.mean, self.std, self.inplace)` internally\n",
    "\n",
    "**Here F doesn't refer to the torch.nn.functional class**, instead to `torchvision.transforms.functional`\n",
    "\n",
    "\n",
    "    Inputs:\n",
    "        tensor - Tensor image of size (C, H, W) to be normalized C- Channel, H - Height, W- Width\n",
    "\t\tmean - Sequence of means for each channel\n",
    "        std - Sequence of standard deviations for each channel\n",
    "        inplace - if the operation should update the original tensor or return a new tensor\n",
    "        \n",
    "\n",
    "##### 2) `normalize` function in `transforms.functional`\n",
    "\n",
    "I'll just refresh on what `normalize` does, it computes \n",
    "<p style=\"font-size:20px;text-align:center\">$\\frac{x - mean}{std}$</p>\n",
    "\n",
    "> for all x ( values ) in the tensor\n",
    "\n",
    "Here, `mean` and `std` denote the mean and standard deviation to be applied\n",
    "\n",
    "\n",
    "* Now, this `normalize` function has been coded in two different ways between versions\n",
    "\n",
    "**A) Colab and Local Machine**\n",
    "\n",
    "def normalize1(tensor, mean, std, inplace=False):\n",
    "    \"\"\"Normalize a tensor image with mean and standard deviation.\n",
    "    Args:\n",
    "        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channel.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Normalized Tensor image.\n",
    "    \"\"\"\n",
    "    mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device) # create mean tensor\n",
    "    std = torch.as_tensor(std, dtype=torch.float32, device=tensor.device) # create standard deviation tensor\n",
    "    tensor.sub_(mean[:, None, None]).div_(std[:, None, None]) # sub mean from the tensor and divide by std (inplace operation)\n",
    "    return tensor\n",
    "\n",
    "Let's see what's happening\n",
    "\n",
    "print(f\"Image tensor shape{img.shape}\\n\") # sample image(tensor) to work on \n",
    "\n",
    "mean = (0.5, 0.5, 0.5)\n",
    "std = (0.5, 0.5, 0.5)\n",
    "\n",
    "mean = torch.as_tensor(mean, dtype=torch.float32, device=tensor.device) # tensor.device - cpu or gpu\n",
    "std = torch.as_tensor(std, dtype=torch.float32, device=tensor.device)\n",
    "\n",
    "print(f\"mean tensor: {mean} \\nshape of mean: {mean.shape}\")\n",
    "\n",
    "print(mean[:, None, None].shape)\n",
    "print(mean[:, None, None])\n",
    "\n",
    "*The below code is the part that causes the error( for some )*\n",
    "\n",
    "tensor0 = img.clone() # create a new image clone as we are going to do inplace operation\n",
    "\n",
    "tensor0.sub_(mean[:, None, None]) \n",
    "\n",
    "\t\tHere, `sub_` throws error as mean[:, None, None] is of shape [3, 1, 1] which gets broadcasted to [3, 28, 28] as shape of tensor is [1, 28, 28] but still can't match the dims.\n",
    "\t\t\n",
    "\t\tNb: Inplace operations in pytorch are always postfixed with a _ , like .add_() or .mul_()\n",
    "\t\t\n",
    "\n",
    "**B) Udacity workspace**\n",
    "\n",
    "def normalize2(tensor, mean, std):\n",
    "    \"\"\"Normalize a tensor image with mean and standard deviation.\n",
    "    Args:\n",
    "        tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        mean (sequence): Sequence of means for each channel.\n",
    "        std (sequence): Sequence of standard deviations for each channely.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Normalized Tensor image.\n",
    "    \"\"\"\n",
    "    for t, m, s in zip(tensor, mean, std):\n",
    "        t.sub_(m).div_(s)\n",
    "    return tensor\n",
    "\n",
    "\t\t\t\n",
    "\t\tHere, `sub_` runs to completion w/o any error due to the use of the `zip` function. \n",
    "\t\tLet's see how the zip function works \n",
    "\n",
    "fruits = ['apple', 'banana', 'orange']\n",
    "colors = ['red', 'yellow', 'orange']\n",
    "vitamins = ['A', 'B', 'C']\n",
    "\n",
    "for fruit, color, vitamin in zip(fruits, colors, vitamins):\n",
    "    print(fruit, color, vitamin)\n",
    "\n",
    "Now, if the arguments to `zip` are of different lengths\n",
    "\n",
    "fruits = ['apple', 'banana']\n",
    "colors = ['red', 'yellow', 'orange']\n",
    "vitamins = ['A', 'B', 'C']\n",
    "\n",
    "for fruit, color, vitamin in zip(fruits, colors, vitamins):\n",
    "    print(fruit, color, vitamin)\n",
    "\n",
    "**the code runs to completion without errors but iterates only upto the smallest arguments( in terms of length ) length**\n",
    "\n",
    "Taking inspiration from the examples above\n",
    "\n",
    "tensor1 = img.clone()\n",
    "\n",
    "print(f\"Shapes:\\n\\ttensor1: {tensor1.shape}, Mean: {mean.shape} , Standard Dev: {std.shape}\\n\")\n",
    "print(f\"Few values in tensor: {tensor[0][0][:5]}\\n\")\n",
    "\n",
    "for t, m, s in zip(tensor1, mean, std):\n",
    "        t.sub_(m).div_(s)\n",
    "        \n",
    "\n",
    "\n",
    "Here, `m` and `s` are scalars and can be broadcasted to a tensor of **[28, 28]**\n",
    "\n",
    "<p style=\"font-size:20px\">AND THIS IS WHY THE `Normalize` RAN FINE ON UDACITY'S WORKSPACE BUT NOT ON COLAB OR MY LOCAL MACHINE FOR THAT MATTER</p>\n",
    "\n",
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
